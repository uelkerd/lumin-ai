# Data Science Track - LUMIN.AI

## Overview
The Data Science track provides statistical analysis and insights from Austria's Democracy Radar surveys, uncovering correlations between transparency initiatives and public trust in governance systems.

## üéØ Track Objectives
- Analyze 10+ waves of Democracy Radar survey data
- Identify statistical correlations between transparency and trust
- Create compelling visualizations for complex governance data
- Develop predictive models for democratic participation

## üìÅ Directory Structure
data-science/
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks for analysis
‚îú‚îÄ‚îÄ src/                    # Reusable analysis scripts
‚îú‚îÄ‚îÄ visualizations/         # Generated charts and graphs
‚îî‚îÄ‚îÄ reports/               # Analysis reports and findings

## üõ†Ô∏è Setup Instructions

### Prerequisites
- Python 3.9+
- Jupyter Lab/Notebook
- Git

### Installation
```bash
# Navigate to data science directory
cd data-science

# Install required packages
pip install -r ../requirements.txt

# Launch Jupyter
jupyter lab
```

## üìì Notebooks Overview

### 1. `01-democracy-radar-eda.ipynb`
- **Purpose**: Initial exploration of Democracy Radar Wave data
- **Key Outputs**: Data quality report, basic statistics, missing value analysis
- **Dependencies**: Raw survey data from `data/raw/democracy-radar/`

### 2. `02-statistical-analysis.ipynb`
- **Purpose**: Core statistical analysis of survey responses
- **Techniques**: Hypothesis testing, confidence intervals, trend analysis
- **Key Findings**: Documented in markdown cells

### 3. `03-correlation-analysis.ipynb`
- **Purpose**: Trust-transparency correlation study
- **Methods**: Pearson/Spearman correlation, regression analysis
- **Visualizations**: Correlation matrices, scatter plots with trend lines

### 4. `04-network-analysis.ipynb`
- **Purpose**: Analyze governance relationship networks
- **Tools**: NetworkX for graph analysis
- **Outputs**: Network visualizations, centrality measures

### 5. `05-governance-comparisons.ipynb`
- **Purpose**: Cross-protocol governance system analysis
- **Data Sources**: Multiple governance platforms
- **Results**: Comparative metrics dashboard

## üìä Key Metrics & Targets

### MVP Phase (Weeks 1-6)
- [ ] Process 3+ Democracy Radar waves
- [ ] Identify 5+ significant correlations
- [ ] Create 10+ publication-quality visualizations
- [ ] Document initial insights report

### Final Phase (Weeks 7-10)
- [ ] Analyze all 10 Democracy Radar waves
- [ ] Build predictive models (R¬≤ > 0.7)
- [ ] Create interactive dashboard visualizations
- [ ] Publish research-quality final report

## üîß Source Code (`src/`)

### `data_cleaning.py`
```python
# Example usage
from src.data_cleaning import clean_democracy_data
df_clean = clean_democracy_data('wave_1.csv')
```

### `statistical_analysis.py`
```python
# Example usage
from src.statistical_analysis import calculate_trust_correlation
correlation = calculate_trust_correlation(df_clean)
```

### `visualization.py`
```python
# Example usage
from src.visualization import create_trust_heatmap
create_trust_heatmap(correlation_matrix, save_path='visualizations/')
```

## üìà Visualization Gallery
- `trust-transparency-correlation.png` - Main finding visualization
- `participation-trends.png` - Time series of engagement
- `governance-networks/` - Network analysis outputs
- `statistical-tests/` - Test result visualizations

## üìã Analysis Checklist

### Data Quality
- [ ] Missing value analysis completed
- [ ] Outlier detection performed
- [ ] Data validation against source
- [ ] Cleaning steps documented

### Statistical Rigor
- [ ] Assumptions tested
- [ ] Multiple testing correction applied
- [ ] Effect sizes reported
- [ ] Confidence intervals included

### Visualization Standards
- [ ] Color-blind friendly palettes
- [ ] Clear titles and labels
- [ ] Source citations included
- [ ] High-resolution exports

## ü§ù Collaboration Points

### With Deep Learning Track
- Provide cleaned text data for NLP models
- Share feature engineering insights
- Validate model predictions against statistical findings

### With Web Development Track
- Supply data endpoints for dashboard
- Define metric calculations
- Provide visualization specifications

### With UX Design Track
- Share user survey insights
- Collaborate on data presentation
- Inform persona development

## üìö Resources & References

### Datasets
- [Austria Democracy Radar](https://data.aussda.at/dataset.xhtml?persistentId=doi:10.11587/GCSLIN)
- [OECD Trust in Government](https://www.oecd.org/gov/trust-in-government.htm)

### Statistical Methods
- [Correlation Analysis Guide](https://www.statisticshowto.com/probability-and-statistics/correlation-analysis/)
- [Network Analysis with Python](https://networkx.org/documentation/stable/tutorial.html)

### Visualization Best Practices
- [Data Visualization Catalogue](https://datavizcatalogue.com/)
- [Seaborn Gallery](https://seaborn.pydata.org/examples/index.html)

## üêõ Common Issues & Solutions

### Issue: Large dataset memory errors
```python
# Solution: Use chunking
import pandas as pd
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process(chunk)
```

### Issue: Slow correlation calculations
```python
# Solution: Use optimized methods
import numpy as np
correlation = np.corrcoef(data.T)  # Faster than pandas.corr()
```

## üìù Contributing Guidelines
1. Create new notebooks with clear numbering
2. Document all analysis steps in markdown
3. Export static visualizations to `visualizations/`
4. Update reports with new findings
5. Commit cleaned data to `data/processed/`

---
**Track Lead**: [Name]
**Last Updated**: [Date]
**Status**: üü¢ Active Development
